{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7ì¼ì°¨: PyTorch ëª¨ë¸ êµ¬ì„± ë° ë°ì´í„° ë¡œë”©\n\n## í•™ìŠµ ëª©í‘œ\n- nn.Moduleë¡œ ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜\n- ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©\n- ì™„ì „í•œ í•™ìŠµ ë£¨í”„ êµ¬í˜„\n- Datasetê³¼ DataLoader í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n\nprint(f'PyTorch ë²„ì „: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ï¿½ï¿½ ì´ë¡  ê°œìš”\n\n### nn.Module\nPyTorchì˜ ëª¨ë“  ì‹ ê²½ë§ì€ `nn.Module`ì„ ìƒì†\n- `__init__()`: ë ˆì´ì–´ ì •ì˜\n- `forward()`: Forward pass ì •ì˜\n- `parameters()`: í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìë™ ê´€ë¦¬\n\n### í•™ìŠµ ë£¨í”„ 4ë‹¨ê³„\n1. **Forward pass**: ì˜ˆì¸¡ê°’ ê³„ì‚°\n2. **Loss ê³„ì‚°**: ì˜ˆì¸¡ê³¼ ì •ë‹µ ë¹„êµ\n3. **Backward pass**: Gradient ê³„ì‚°\n4. **Parameter ì—…ë°ì´íŠ¸**: Optimizerë¡œ ê°€ì¤‘ì¹˜ ê°±ì‹ \n\n### Dataset & DataLoader\n- `Dataset`: ë°ì´í„°ì™€ ë¼ë²¨ ë°˜í™˜\n- `DataLoader`: ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì œê³µ, ì„ê¸°, ë³‘ë ¬ ë¡œë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 1. nn.Module ê¸°ë³¸\n\n### 1.1 ê°„ë‹¨í•œ ì„ í˜• ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module ìƒì†í•˜ì—¬ ëª¨ë¸ ì •ì˜\nclass LinearModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(LinearModel, self).__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n    \n    def forward(self, x):\n        return self.linear(x)\n\n# ëª¨ë¸ ìƒì„±\nmodel = LinearModel(input_dim=1, output_dim=1)\nprint('ëª¨ë¸ êµ¬ì¡°:')\nprint(model)\nprint()\n\n# íŒŒë¼ë¯¸í„° í™•ì¸\nfor name, param in model.named_parameters():\n    print(f'{name}: {param.shape}')\n    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ë‹¤ì¸µ ì‹ ê²½ë§ (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n\nmlp = MLP(input_dim=10, hidden_dim=20, output_dim=2)\nprint('MLP êµ¬ì¡°:')\nprint(mlp)\nprint()\n\n# í…ŒìŠ¤íŠ¸ ì…ë ¥\ntest_input = torch.randn(5, 10)  # ë°°ì¹˜ 5, íŠ¹ì„± 10\noutput = mlp(test_input)\nprint(f'ì…ë ¥ shape: {test_input.shape}')\nprint(f'ì¶œë ¥ shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 2. ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n\n### 2.1 ì†ì‹¤ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE Loss (íšŒê·€)\nmse_loss = nn.MSELoss()\npred = torch.tensor([1.0, 2.0, 3.0])\ntarget = torch.tensor([1.5, 2.5, 2.5])\nloss = mse_loss(pred, target)\nprint(f'MSE Loss: {loss.item():.4f}')\nprint(f'ê³„ì‚°: mean((pred - target)Â²) = mean([0.25, 0.25, 0.25]) = 0.25')\nprint()\n\n# CrossEntropy Loss (ë¶„ë¥˜)\nce_loss = nn.CrossEntropyLoss()\nlogits = torch.randn(3, 5)  # 3ê°œ ìƒ˜í”Œ, 5ê°œ í´ë˜ìŠ¤\nlabels = torch.tensor([1, 0, 4])  # ì •ë‹µ ë ˆì´ë¸”\nloss = ce_loss(logits, labels)\nprint(f'CrossEntropy Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ì˜µí‹°ë§ˆì´ì €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(1, 1)\n\n# SGD\noptimizer_sgd = optim.SGD(model.parameters(), lr=0.01)\nprint('SGD Optimizer:')\nprint(optimizer_sgd)\nprint()\n\n# Adam (ë” ë§ì´ ì‚¬ìš©ë¨)\noptimizer_adam = optim.Adam(model.parameters(), lr=0.001)\nprint('Adam Optimizer:')\nprint(optimizer_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 3. ì™„ì „í•œ í•™ìŠµ ë£¨í”„\n\n### 3.1 ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ í˜• ë°ì´í„° ìƒì„±: y = 3x + 1 + noise\ntorch.manual_seed(42)\nx_train = torch.randn(100, 1)\ny_train = 3 * x_train + 1 + 0.2 * torch.randn(100, 1)\n\nprint(f'í›ˆë ¨ ë°ì´í„°: x {x_train.shape}, y {y_train.shape}')\nprint(f'ëª©í‘œ: y = 3x + 1ì„ í•™ìŠµ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸, ì†ì‹¤, ì˜µí‹°ë§ˆì´ì €\nmodel = LinearModel(1, 1)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nnum_epochs = 100\n\nfor epoch in range(num_epochs):\n    # 1. Forward pass\n    y_pred = model(x_train)\n    \n    # 2. Loss ê³„ì‚°\n    loss = criterion(y_pred, y_train)\n    \n    # 3. Backward pass\n    optimizer.zero_grad()  # Gradient ì´ˆê¸°í™”\n    loss.backward()         # Gradient ê³„ì‚°\n    \n    # 4. Parameter ì—…ë°ì´íŠ¸\n    optimizer.step()\n    \n    if (epoch + 1) % 20 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\nprint()\nprint('í•™ìŠµëœ íŒŒë¼ë¯¸í„°:')\nfor name, param in model.named_parameters():\n    print(f'{name}: {param.data.numpy()}')\n\nprint('\\nëª©í‘œ: weight=3, bias=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 4. Datasetê³¼ DataLoader\n\n### 4.1 ì»¤ìŠ¤í…€ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n    \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx]\n\n# Dataset ìƒì„±\ndataset = CustomDataset(x_train, y_train)\nprint(f'Dataset í¬ê¸°: {len(dataset)}')\nprint(f'ì²« ë²ˆì§¸ ìƒ˜í”Œ: {dataset[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 DataLoader ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n\nprint(f'ì´ ë°°ì¹˜ ìˆ˜: {len(dataloader)}')\nprint()\n\n# ë°°ì¹˜ ìˆœíšŒ\nfor batch_idx, (batch_x, batch_y) in enumerate(dataloader):\n    print(f'Batch {batch_idx+1}: x {batch_x.shape}, y {batch_y.shape}')\n    if batch_idx == 2:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥\n        print('...')\n        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 DataLoaderë¡œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒˆ ëª¨ë¸\nmodel = LinearModel(1, 1)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nnum_epochs = 50\n\nfor epoch in range(num_epochs):\n    epoch_loss = 0\n    \n    for batch_x, batch_y in dataloader:\n        # Forward\n        y_pred = model(batch_x)\n        loss = criterion(y_pred, batch_y)\n        \n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n    \n    if (epoch + 1) % 10 == 0:\n        avg_loss = epoch_loss / len(dataloader)\n        print(f'Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}')\n\nprint('\\në°°ì¹˜ í•™ìŠµ ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 5. ì´ì§„ ë¶„ë¥˜ ì˜ˆì œ\n\n### 5.1 ë°ì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D ì  ë¶„ë¥˜ (x2 > x1ì´ë©´ í´ë˜ìŠ¤ 1)\ntorch.manual_seed(42)\nx_data = torch.randn(200, 2)\ny_data = (x_data[:, 1] > x_data[:, 0]).long()  # 0 ë˜ëŠ” 1\n\nprint(f'ë°ì´í„°: {x_data.shape}')\nprint(f'ë¼ë²¨: {y_data.shape}')\nprint(f'í´ë˜ìŠ¤ 0: {(y_data == 0).sum()}, í´ë˜ìŠ¤ 1: {(y_data == 1).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ë¶„ë¥˜ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(2, 10)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(10, 2)  # 2ê°œ í´ë˜ìŠ¤\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x  # Logits (CrossEntropyLossê°€ softmax í¬í•¨)\n\nmodel = BinaryClassifier()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\nprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 í•™ìŠµ ë° í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset & DataLoader\ndataset = CustomDataset(x_data, y_data)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nnum_epochs = 100\n\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0\n    correct = 0\n    total = 0\n    \n    for batch_x, batch_y in dataloader:\n        # Forward\n        outputs = model(batch_x)\n        loss = criterion(outputs, batch_y)\n        \n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n        # ì •í™•ë„ ê³„ì‚°\n        _, predicted = torch.max(outputs, 1)\n        total += batch_y.size(0)\n        correct += (predicted == batch_y).sum().item()\n    \n    if (epoch + 1) % 20 == 0:\n        accuracy = 100 * correct / total\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%')\n\nprint('\\ní•™ìŠµ ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¥ ì—°ìŠµ ë¬¸ì œ\n\n### ë¬¸ì œ 1: íšŒê·€ ëª¨ë¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: y = 2xâ‚ + 3xâ‚‚ + 1ë¥¼ í•™ìŠµí•˜ëŠ” ëª¨ë¸ ë§Œë“¤ê¸°\n# 1. ë°ì´í„° ìƒì„±\n# 2. ëª¨ë¸ ì •ì˜\n# 3. í•™ìŠµ\n\n# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•´ë‹µ\ntorch.manual_seed(42)\nx = torch.randn(100, 2)\ny = 2*x[:, 0:1] + 3*x[:, 1:2] + 1 + 0.1*torch.randn(100, 1)\n\nmodel = LinearModel(2, 1)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nfor epoch in range(200):\n    y_pred = model(x)\n    loss = criterion(y_pred, y)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch+1) % 50 == 0:\n        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n\nprint('\\ní•™ìŠµëœ ê°€ì¤‘ì¹˜:')\nprint(model.linear.weight.data)\nprint('ëª©í‘œ: [2, 3]')\nprint('\\ní¸í–¥:')\nprint(model.linear.bias.data)\nprint('ëª©í‘œ: 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ 7ì¼ í•™ìŠµ ì™„ë£Œ!\n\n### ë°°ìš´ ë‚´ìš© ì´ì •ë¦¬\n\n**Day 1-3: NumPy ê¸°ì´ˆ**\n- ë°°ì—´ ì¡°ì‘, ì°¨ì› ë³€í™˜\n- ë¸Œë¡œë“œìºìŠ¤íŒ…, í–‰ë ¬ ì—°ì‚°\n- ì§‘ê³„, í•„í„°ë§\n\n**Day 4-5: ì„ í˜•ëŒ€ìˆ˜**\n- ì—­í–‰ë ¬, í–‰ë ¬ì‹, ë­í¬\n- SVD, ê³ ìœ ê°’/ê³ ìœ ë²¡í„°\n- ìœ ì‚¬ì—­í–‰ë ¬, PSD\n\n**Day 6-7: PyTorch**\n- Tensor, Autograd\n- nn.Module, nn.Linear\n- Loss, Optimizer\n- Dataset, DataLoader\n\n### ë‹¤ìŒ ë‹¨ê³„\n1. CNN, RNN ë“± ê³ ê¸‰ ì•„í‚¤í…ì²˜\n2. ì‹¤ì œ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤ìŠµ\n3. GPU í•™ìŠµ, ëª¨ë¸ ì €ì¥/ë¡œë“œ\n4. Transfer Learning\n\n**ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰**\në”¥ëŸ¬ë‹ ê¸°ì´ˆë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}