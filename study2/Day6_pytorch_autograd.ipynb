{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6ì¼ì°¨: PyTorch í…ì„œì™€ Autograd ê¸°ë³¸\n\n## í•™ìŠµ ëª©í‘œ\n- PyTorch í…ì„œ ê¸°ë³¸ ì‚¬ìš©ë²• í•™ìŠµ\n- Autograd(ìë™ ë¯¸ë¶„) ë©”ì»¤ë‹ˆì¦˜ ì´í•´\n- Gradient ê³„ì‚° ë° ì—­ì „íŒŒ ì‹¤ìŠµ\n- Gradient ì¶”ì  ì œì–´í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\nimport numpy as np\nprint(f'PyTorch ë²„ì „: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ ì´ë¡  ê°œìš”\n\n### PyTorch Tensor\n- NumPyì™€ ìœ ì‚¬í•œ ë‹¤ì°¨ì› ë°°ì—´\n- **GPU ì—°ì‚° ì§€ì›**\n- **ìë™ ë¯¸ë¶„ ì§€ì›** (autograd)\n\n### Autograd (ìë™ ë¯¸ë¶„)\n- ì—°ì‚° ê·¸ë˜í”„ ìë™ ìƒì„±\n- `.backward()` í˜¸ì¶œë¡œ gradient ê³„ì‚°\n- ë”¥ëŸ¬ë‹ ì—­ì „íŒŒì˜ í•µì‹¬\n\n### ì£¼ìš” ê°œë…\n- `requires_grad=True`: gradient ì¶”ì  ì‹œì‘\n- `.backward()`: gradient ê³„ì‚°\n- `.grad`: ê³„ì‚°ëœ gradient ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 1. PyTorch í…ì„œ ê¸°ë³¸\n\n### 1.1 í…ì„œ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° í…ì„œ ìƒì„±\nt = torch.tensor([1, 2, 3, 4, 5])\nprint('í…ì„œ:', t)\nprint(f'íƒ€ì…: {type(t)}')\nprint(f'dtype: {t.dtype}')\nprint(f'shape: {t.shape}')\nprint(f'device: {t.device}')  # cpu ë˜ëŠ” cuda\nprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì–‘í•œ í…ì„œ ìƒì„± ë°©ë²•\nzeros = torch.zeros(2, 3)\nones = torch.ones(3, 2)\nrand = torch.rand(2, 2)  # [0, 1) ê· ë“±ë¶„í¬\nrandn = torch.randn(2, 2)  # í‘œì¤€ì •ê·œë¶„í¬\n\nprint('zeros (2Ã—3):'); print(zeros)\nprint('\\nones (3Ã—2):'); print(ones)\nprint('\\nrand (2Ã—2):'); print(rand)\nprint('\\nrandn (2Ã—2):'); print(randn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 NumPyì™€ ìƒí˜¸ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy â†’ PyTorch\nnp_array = np.array([[1, 2], [3, 4]])\ntorch_tensor = torch.from_numpy(np_array)\n\nprint('NumPy ë°°ì—´:')\nprint(np_array)\nprint('\\nPyTorch í…ì„œ:')\nprint(torch_tensor)\nprint()\n\n# PyTorch â†’ NumPy\nback_to_numpy = torch_tensor.numpy()\nprint('ë‹¤ì‹œ NumPyë¡œ:')\nprint(back_to_numpy)\nprint()\n\nprint('âš ï¸ ì£¼ì˜: ë©”ëª¨ë¦¬ë¥¼ ê³µìœ í•©ë‹ˆë‹¤!')\nnp_array[0, 0] = 999\nprint('NumPy ìˆ˜ì • í›„ í…ì„œ:', torch_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 2. Autograd ê¸°ë³¸\n\n### 2.1 ê°„ë‹¨í•œ ë¯¸ë¶„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = xÂ² + 3x + 5ì—ì„œ dy/dx ê³„ì‚°\nx = torch.tensor(2.0, requires_grad=True)\nprint(f'x = {x}')\nprint(f'requires_grad: {x.requires_grad}')\nprint()\n\n# Forward pass\ny = x**2 + 3*x + 5\nprint(f'y = xÂ² + 3x + 5 = {y.item()}')\nprint()\n\n# Backward pass (gradient ê³„ì‚°)\ny.backward()\n\nprint('Gradient ê³„ì‚° ì™„ë£Œ!')\nprint(f'dy/dx = 2x + 3 = 2Ã—{x.item()} + 3 = {x.grad.item()}')\nprint()\nprint(f'ì‹¤ì œ gradient: {x.grad.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ë‹¤ë³€ìˆ˜ í•¨ìˆ˜ì˜ gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = xÂ² + 2xy + yÂ²ì—ì„œ âˆ‚z/âˆ‚x, âˆ‚z/âˆ‚y\nx = torch.tensor(1.0, requires_grad=True)\ny = torch.tensor(2.0, requires_grad=True)\n\nprint(f'x = {x.item()}, y = {y.item()}')\nprint()\n\n# Forward\nz = x**2 + 2*x*y + y**2\nprint(f'z = xÂ² + 2xy + yÂ² = {z.item()}')\nprint()\n\n# Backward\nz.backward()\n\nprint('Gradients:')\nprint(f'âˆ‚z/âˆ‚x = 2x + 2y = 2Ã—{x.item()} + 2Ã—{y.item()} = {x.grad.item()}')\nprint(f'âˆ‚z/âˆ‚y = 2x + 2y = 2Ã—{x.item()} + 2Ã—{y.item()} = {y.grad.item()}')\nprint()\nprint('ìˆ˜ì‹: âˆ‚z/âˆ‚x = âˆ‚z/âˆ‚y = 2x + 2y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ë²¡í„° ë° í–‰ë ¬ ì—°ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²¡í„° ë‚´ì ì˜ gradient\nv = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\nw = torch.tensor([4.0, 5.0, 6.0])\n\nprint(f'v = {v}')\nprint(f'w = {w}')\nprint()\n\n# ë‚´ì : vÂ·w\ndot_product = torch.dot(v, w)\nprint(f'vÂ·w = {dot_product.item()}')\nprint()\n\ndot_product.backward()\n\nprint('âˆ‚(vÂ·w)/âˆ‚v = w')\nprint(f'gradient: {v.grad}')\nprint(f'wì™€ ì¼ì¹˜: {torch.allclose(v.grad, w)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 3. Gradient ì œì–´\n\n### 3.1 torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n\nprint('ì¼ë°˜ ì—°ì‚° (gradient ì¶”ì ):')\ny = x * 2\nprint(f'y.requires_grad: {y.requires_grad}')\nprint()\n\nprint('torch.no_grad() ì‚¬ìš©:')\nwith torch.no_grad():\n    z = x * 2\n    print(f'z.requires_grad: {z.requires_grad}')\nprint()\nprint('âš ï¸ Inference ì‹œ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ no_grad ì‚¬ìš©!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Gradient ëˆ„ì ê³¼ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3.0, requires_grad=True)\n\n# ì²« ë²ˆì§¸ backward\ny1 = x ** 2\ny1.backward()\nprint(f'ì²« ë²ˆì§¸ backward í›„ x.grad: {x.grad}')\n\n# gradient ì´ˆê¸°í™” ì—†ì´ ë‘ ë²ˆì§¸ backward\ny2 = x ** 3\ny2.backward()\nprint(f'ë‘ ë²ˆì§¸ backward í›„ x.grad: {x.grad}')\nprint('â†’ Gradientê°€ ëˆ„ì ë¨!')\nprint()\n\n# Gradient ì´ˆê¸°í™”\nx.grad.zero_()\nprint(f'ì´ˆê¸°í™” í›„ x.grad: {x.grad}')\nprint()\nprint('ğŸ’¡ í•™ìŠµ ë£¨í”„ì—ì„œëŠ” ë§¤ iterationë§ˆë‹¤ optimizer.zero_grad() í•„ìš”!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š 4. ì‹¤ì „ ì˜ˆì œ: ì„ í˜• íšŒê·€\n\n### 4.1 ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°: y = 3x + 1 + noise\ntorch.manual_seed(42)\nx_data = torch.randn(100, 1)\ny_data = 3 * x_data + 1 + 0.1 * torch.randn(100, 1)\n\nprint('ë°ì´í„° shape:')\nprint(f'x: {x_data.shape}')\nprint(f'y: {y_data.shape}')\nprint()\nprint('ëª©í‘œ: y = 3x + 1ì„ í•™ìŠµìœ¼ë¡œ ì°¾ê¸°')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ëª¨ë¸ íŒŒë¼ë¯¸í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”\nw = torch.randn(1, 1, requires_grad=True)\nb = torch.zeros(1, 1, requires_grad=True)\n\nprint(f'ì´ˆê¸° w: {w.item():.4f}')\nprint(f'ì´ˆê¸° b: {b.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 í•™ìŠµ ë£¨í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\nnum_epochs = 100\n\nfor epoch in range(num_epochs):\n    # Forward pass\n    y_pred = x_data @ w + b\n    \n    # Loss (MSE)\n    loss = torch.mean((y_pred - y_data) ** 2)\n    \n    # Backward pass\n    loss.backward()\n    \n    # Update (gradient descent)\n    with torch.no_grad():\n        w -= learning_rate * w.grad\n        b -= learning_rate * b.grad\n    \n    # Gradient ì´ˆê¸°í™”\n    w.grad.zero_()\n    b.grad.zero_()\n    \n    if (epoch + 1) % 20 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, w: {w.item():.4f}, b: {b.item():.4f}')\n\nprint()\nprint(f'ìµœì¢… w: {w.item():.4f} (ëª©í‘œ: 3.0)')\nprint(f'ìµœì¢… b: {b.item():.4f} (ëª©í‘œ: 1.0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¥ ì—°ìŠµ ë¬¸ì œ\n\n### ë¬¸ì œ 1: ë‹¨ì¼ ë³€ìˆ˜ ë¯¸ë¶„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: f(x) = xÂ³ - 2xÂ² + 5x - 1ì—ì„œ\n# x = 2ì¼ ë•Œ df/dxë¥¼ ê³„ì‚°í•˜ì„¸ìš”\n\n# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•´ë‹µ\nx = torch.tensor(2.0, requires_grad=True)\nf = x**3 - 2*x**2 + 5*x - 1\n\nf.backward()\n\nprint(f'f(x) = xÂ³ - 2xÂ² + 5x - 1')\nprint(f'f\\'(x) = 3xÂ² - 4x + 5')\nprint(f'\\nx = 2ì¼ ë•Œ:')\nprint(f'f(2) = {f.item()}')\nprint(f'f\\'(2) = 3Ã—4 - 4Ã—2 + 5 = 9')\nprint(f'ê³„ì‚°ëœ gradient: {x.grad.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 2: ë²¡í„° í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: x = [1, 2, 3]ì¼ ë•Œ\n# f(x) = Î£xáµ¢Â²ì˜ gradientë¥¼ êµ¬í•˜ì„¸ìš”\n\n# ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±í•œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•´ë‹µ\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\nf = torch.sum(x ** 2)\n\nf.backward()\n\nprint(f'f(x) = Î£xáµ¢Â² = xâ‚Â² + xâ‚‚Â² + xâ‚ƒÂ²')\nprint(f'âˆ‚f/âˆ‚xáµ¢ = 2xáµ¢')\nprint(f'\\nx = [1, 2, 3]')\nprint(f'gradient = [2Ã—1, 2Ã—2, 2Ã—3] = {x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ë³µìŠµ\n\n### í•µì‹¬ ì •ë¦¬\n\n**PyTorch Tensor**\n- GPU ì—°ì‚° ê°€ëŠ¥ (`.to('cuda')`)\n- NumPy í˜¸í™˜ (`.numpy()`, `torch.from_numpy()`)\n- ìë™ ë¯¸ë¶„ ì§€ì›\n\n**Autograd**\n- `requires_grad=True`: ì¶”ì  ì‹œì‘\n- `.backward()`: gradient ê³„ì‚°\n- `.grad`: gradient ê°’\n- `zero_()`: gradient ì´ˆê¸°í™”\n\n**ì£¼ì˜ì‚¬í•­**\n1. Gradient ëˆ„ì  - ë§¤ë²ˆ ì´ˆê¸°í™” í•„ìš”\n2. Inference ì‹œ `torch.no_grad()` ì‚¬ìš©\n3. `.item()`ìœ¼ë¡œ ìŠ¤ì¹¼ë¼ ê°’ ì¶”ì¶œ\n\n### ë‹¤ìŒ í•™ìŠµ\nDay 7: nn.Module, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €ë¡œ ì™„ì „í•œ í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}