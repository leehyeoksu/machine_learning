{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 머신러닝을 위한 확률과 통계 기초 개념 정리\n",
                "\n",
                "## 학습 목표\n",
                "- 확률의 정의와 조건부 확률 완벽 이해\n",
                "- 확률변수, 기댓값, 분산 등 통계량 마스터\n",
                "- 주요 확률분포들의 특성과 ML 활용\n",
                "- 베이즈 정리와 중심극한정리의 직관적 이해\n",
                "- Python 코드를 통한 실습과 시각화\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy import stats\n",
                "\n",
                "# 설정\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (10, 6)\n",
                "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 확률의 정의와 기본 공리\n",
                "\n",
                "### 1.1 확률이란?\n",
                "\n",
                "**확률(Probability)**은 0과 1 사이의 값으로, 어떤 사건이 발생할 가능성의 정도를 나타냅니다.\n",
                "\n",
                "### 1.2 Kolmogorov 공리\n",
                "\n",
                "1. **비음성**: $P(A) \\geq 0$ for all events $A$\n",
                "2. **정규화**: $P(S) = 1$ (전체 표본공간의 확률은 1)\n",
                "3. **가산 가법성**: 상호 배타적 사건 $A_1, A_2, \\ldots$에 대해 \n",
                "   $$P(A_1 \\cup A_2 \\cup \\cdots) = P(A_1) + P(A_2) + \\cdots$$\n",
                "\n",
                "### 1.3 기본 성질\n",
                "\n",
                "- **여사건**: $P(A^c) = 1 - P(A)$\n",
                "- **합사건**: $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n",
                "- **독립**: $A \\perp B \\iff P(A \\cap B) = P(A)P(B)$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 예제: 주사위 던지기\n",
                "outcomes = np.arange(1, 7)\n",
                "probs = np.ones(6) / 6\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.bar(outcomes, probs, color='steelblue', alpha=0.7, edgecolor='black')\n",
                "plt.xlabel('주사위 눈금')\n",
                "plt.ylabel('확률')\n",
                "plt.title('균등 분포: 공정한 주사위')\n",
                "plt.ylim(0, 0.3)\n",
                "for i, (x, y) in enumerate(zip(outcomes, probs)):\n",
                "    plt.text(x, y + 0.01, f'1/6', ha='center')\n",
                "plt.show()\n",
                "\n",
                "print(\"확률 공리 검증:\")\n",
                "print(f\"1. 모든 확률 >= 0: {np.all(probs >= 0)}\")\n",
                "print(f\"2. 전체 확률 = 1: {np.sum(probs):.4f}\")\n",
                "print(f\"3. 합사건: P(1 or 2) = {probs[0] + probs[1]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 조건부 확률과 베이즈 정리\n",
                "\n",
                "### 2.1 조건부 확률 (Conditional Probability)\n",
                "\n",
                "사건 $B$가 일어났다는 조건 하에 사건 $A$가 일어날 확률:\n",
                "\n",
                "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\quad P(B) > 0$$\n",
                "\n",
                "**직관**: 표본공간이 $B$로 축소된 상황에서 $A$의 확률을 재정규화\n",
                "\n",
                "### 2.2 곱셈 규칙\n",
                "\n",
                "$$P(A \\cap B) = P(A|B)P(B) = P(B|A)P(A)$$\n",
                "\n",
                "### 2.3 베이즈 정리 (Bayes' Theorem)\n",
                "\n",
                "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
                "\n",
                "- $P(A)$: **Prior** (사전 확률)\n",
                "- $P(B|A)$: **Likelihood** (가능도)\n",
                "- $P(B)$: **Evidence** (증거)\n",
                "- $P(A|B)$: **Posterior** (사후 확률)\n",
                "\n",
                "### 2.4 전확률 공식 (Law of Total Probability)\n",
                "\n",
                "$$P(B) = \\sum_{i=1}^{n} P(B|A_i) P(A_i)$$\n",
                "\n",
                "**ML에서의 활용**: 나이브 베이즈 분류기, 베이지안 네트워크, 스팸 필터 등"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 베이즈 정리 예제: 질병 진단\n",
                "# A: 질병이 있다, B: 검사 결과 양성\n",
                "\n",
                "P_disease = 0.01  # Prior: 질병 유병률 1%\n",
                "P_positive_given_disease = 0.95  # Likelihood: 민감도\n",
                "P_negative_given_no_disease = 0.90  # 특이도\n",
                "P_positive_given_no_disease = 1 - P_negative_given_no_disease  # 위양성\n",
                "\n",
                "# Evidence: 전체 양성 확률\n",
                "P_positive = (P_positive_given_disease * P_disease + \n",
                "              P_positive_given_no_disease * (1 - P_disease))\n",
                "\n",
                "# Posterior: 양성일 때 실제로 질병이 있을 확률\n",
                "P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive\n",
                "\n",
                "print(\"=== 베이즈 정리: 질병 진단 ===\")\n",
                "print(f\"Prior P(질병) = {P_disease:.4f}\")\n",
                "print(f\"Likelihood P(양성|질병) = {P_positive_given_disease:.4f}\")\n",
                "print(f\"위양성 P(양성|건강) = {P_positive_given_no_disease:.4f}\")\n",
                "print(f\"Evidence P(양성) = {P_positive:.4f}\")\n",
                "print(f\"\\nPosterior P(질병|양성) = {P_disease_given_positive:.4f}\")\n",
                "print(f\"\\n해석: 검사 결과가 양성이어도 실제 질병일 확률은 {P_disease_given_positive*100:.1f}%\")\n",
                "print(\"→ 낮은 유병률 때문! (Base rate fallacy)\")\n",
                "\n",
                "# 시각화\n",
                "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
                "labels = ['질병 있음', '질병 없음']\n",
                "colors = ['#ff6b6b', '#51cf66']\n",
                "\n",
                "# Prior\n",
                "ax[0].pie([P_disease, 1 - P_disease], labels=labels, colors=colors, autopct='%1.2f%%')\n",
                "ax[0].set_title('Prior: 검사 전 확률')\n",
                "\n",
                "# Posterior\n",
                "ax[1].pie([P_disease_given_positive, 1 - P_disease_given_positive], \n",
                "          labels=labels, colors=colors, autopct='%1.2f%%')\n",
                "ax[1].set_title('Posterior: 양성 결과 후 확률')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 확률변수 (Random Variable)\n",
                "\n",
                "### 3.1 정의\n",
                "\n",
                "**확률변수**는 표본공간의 각 결과를 수치로 매핑하는 함수 $X: \\Omega \\rightarrow \\mathbb{R}$\n",
                "\n",
                "### 3.2 이산형 vs 연속형\n",
                "\n",
                "**이산 확률변수 (Discrete)**:\n",
                "- 가산개의 값 (예: 동전 던지기, 주사위)\n",
                "- **PMF (Probability Mass Function)**: $p(x) = P(X = x)$\n",
                "- 성질: $\\sum_x p(x) = 1$\n",
                "\n",
                "**연속 확률변수 (Continuous)**:\n",
                "- 연속 범위의 값 (예: 키, 몸무게)\n",
                "- **PDF (Probability Density Function)**: $f(x)$\n",
                "- 성질: $\\int_{-\\infty}^{\\infty} f(x) dx = 1$\n",
                "- $P(a \\leq X \\leq b) = \\int_a^b f(x) dx$\n",
                "- 중요: $P(X = a) = 0$ (특정 값의 확률은 0!)\n",
                "\n",
                "**ML에서의 활용**: 모델 예측값, 손실 함수, 가중치 초기화 등"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 이산형: 이항 분포 vs 연속형: 정규 분포\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# 이산형: Binomial\n",
                "n, p = 10, 0.5\n",
                "x_discrete = np.arange(0, n+1)\n",
                "pmf = stats.binom.pmf(x_discrete, n, p)\n",
                "\n",
                "axes[0].bar(x_discrete, pmf, color='steelblue', alpha=0.7, edgecolor='black')\n",
                "axes[0].set_xlabel('X (성공 횟수)')\n",
                "axes[0].set_ylabel('P(X = x)')\n",
                "axes[0].set_title(f'이산형: Binomial(n={n}, p={p})')\n",
                "axes[0].grid(alpha=0.3)\n",
                "\n",
                "# 연속형: Normal\n",
                "mu, sigma = 0, 1\n",
                "x_continuous = np.linspace(-4, 4, 1000)\n",
                "pdf = stats.norm.pdf(x_continuous, mu, sigma)\n",
                "\n",
                "axes[1].plot(x_continuous, pdf, 'r-', linewidth=2)\n",
                "axes[1].fill_between(x_continuous, pdf, alpha=0.3, color='red')\n",
                "axes[1].set_xlabel('X')\n",
                "axes[1].set_ylabel('f(x)')\n",
                "axes[1].set_title(f'연속형: Normal(μ={mu}, σ²={sigma**2})')\n",
                "axes[1].grid(alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"=== 확률 계산 ===\")\n",
                "print(f\"이산형: P(X = 5) = {pmf[5]:.4f}\")\n",
                "prob_continuous = stats.norm.cdf(1, mu, sigma) - stats.norm.cdf(-1, mu, sigma)\n",
                "print(f\"연속형: P(-1 ≤ X ≤ 1) = {prob_continuous:.4f} (약 68%, 정규분포의 1σ 구간)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 기댓값, 분산, 공분산, 상관계수\n",
                "\n",
                "### 4.1 기댓값 (Expectation, Mean)\n",
                "\n",
                "확률분포의 **평균적인 값**, 가중평균:\n",
                "\n",
                "**이산형**: $E[X] = \\sum_x x \\cdot P(X = x)$\n",
                "\n",
                "**연속형**: $E[X] = \\int_{-\\infty}^{\\infty} x f(x) dx$\n",
                "\n",
                "**직관**: 무한히 반복 관측했을 때의 평균 (대수의 법칙)\n",
                "\n",
                "### 4.2 분산 (Variance)과 표준편차\n",
                "\n",
                "평균 주변 **산포도**:\n",
                "\n",
                "$$\\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$\n",
                "\n",
                "**표준편차**: $\\sigma(X) = \\sqrt{\\text{Var}(X)}$\n",
                "\n",
                "### 4.3 공분산 (Covariance)\n",
                "\n",
                "두 변수의 **함께 변동하는 정도**:\n",
                "\n",
                "$$\\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])]$$\n",
                "\n",
                "- 양수: 함께 증가\n",
                "- 음수: 반대로 움직임\n",
                "- 0: 선형 관계 없음\n",
                "\n",
                "### 4.4 상관계수 (Correlation Coefficient)\n",
                "\n",
                "공분산을 **정규화**:\n",
                "\n",
                "$$\\rho_{X,Y} = \\frac{\\text{Cov}(X, Y)}{\\sigma(X) \\sigma(Y)}, \\quad -1 \\leq \\rho \\leq 1$$\n",
                "\n",
                "**ML에서의 활용**: 특성 선택, PCA, 다중공선성 제거, 협업 필터링 등"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 대수의 법칙 (Law of Large Numbers) 시뮬레이션\n",
                "# 동전 던지기 1000번\n",
                "n_trials = 1000\n",
                "p = 0.5  # 앞면 확률\n",
                "\n",
                "flips = np.random.binomial(1, p, n_trials)\n",
                "cumulative_avg = np.cumsum(flips) / (np.arange(n_trials) + 1)\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "plt.plot(cumulative_avg, linewidth=2, label='누적 평균 (앞면 비율)')\n",
                "plt.axhline(p, color='r', linestyle='--', linewidth=2, label=f'이론적 확률 p={p}')\n",
                "plt.xlabel('시행 횟수')\n",
                "plt.ylabel('앞면의 누적 비율')\n",
                "plt.title('대수의 법칙: 동전 던지기 실험')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "print(f\"1000번 후 누적 평균: {cumulative_avg[-1]:.4f}\")\n",
                "print(f\"이론적 기댓값: {p}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 공분산과 상관계수 시각화\n",
                "mean = [0, 0]\n",
                "cov_high = [[1, 0.8], [0.8, 1]]  # 높은 상관관계\n",
                "cov_zero = [[1, 0], [0, 1]]  # 독립\n",
                "\n",
                "samples_corr = np.random.multivariate_normal(mean, cov_high, 1000)\n",
                "samples_indep = np.random.multivariate_normal(mean, cov_zero, 1000)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# 상관관계 있음\n",
                "axes[0].scatter(samples_corr[:, 0], samples_corr[:, 1], alpha=0.5, s=10)\n",
                "axes[0].set_xlabel('X')\n",
                "axes[0].set_ylabel('Y')\n",
                "axes[0].set_title('높은 상관관계 (ρ = 0.8)')\n",
                "axes[0].grid(alpha=0.3)\n",
                "axes[0].axis('equal')\n",
                "\n",
                "# 독립\n",
                "axes[1].scatter(samples_indep[:, 0], samples_indep[:, 1], alpha=0.5, s=10, color='orange')\n",
                "axes[1].set_xlabel('X')\n",
                "axes[1].set_ylabel('Y')\n",
                "axes[1].set_title('독립 (ρ = 0)')\n",
                "axes[1].grid(alpha=0.3)\n",
                "axes[1].axis('equal')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 상관계수 계산\n",
                "corr_high = np.corrcoef(samples_corr.T)[0, 1]\n",
                "corr_zero = np.corrcoef(samples_indep.T)[0, 1]\n",
                "print(f\"높은 상관: ρ = {corr_high:.4f}\")\n",
                "print(f\"독립: ρ = {corr_zero:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 주요 확률분포\n",
                "\n",
                "### 5.1 베르누이 분포 (Bernoulli)\n",
                "\n",
                "**설명**: 1번 시행, 성공(1)/실패(0)\n",
                "\n",
                "- $P(X = 1) = p$, $P(X = 0) = 1 - p$\n",
                "- $E[X] = p$\n",
                "- $\\text{Var}(X) = p(1-p)$\n",
                "\n",
                "**ML 활용**: 이진 분류 레이블, 로지스틱 회귀, 드롭아웃"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 베르누이 분포 시뮬레이션\n",
                "p = 0.6\n",
                "n_samples = 10000\n",
                "samples = np.random.binomial(1, p, n_samples)\n",
                "\n",
                "print(f\"=== Bernoulli(p={p}) ===\")\n",
                "print(f\"이론 E[X] = {p}\")\n",
                "print(f\"이론 Var(X) = {p*(1-p):.4f}\")\n",
                "print(f\"샘플 평균 = {samples.mean():.4f}\")\n",
                "print(f\"샘플 분산 = {samples.var():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 이항분포 (Binomial)\n",
                "\n",
                "**설명**: $n$번 독립 시행에서 성공 횟수\n",
                "\n",
                "$$P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n",
                "\n",
                "- $E[X] = np$\n",
                "- $\\text{Var}(X) = np(1-p)$\n",
                "\n",
                "**ML 활용**: 베이지안 추론, A/B 테스트, 정확도 분포 근사"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 이항분포 시각화\n",
                "n, p = 20, 0.7\n",
                "k_values = np.arange(0, n+1)\n",
                "pmf = stats.binom.pmf(k_values, n, p)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.bar(k_values, pmf, alpha=0.7, color='orange', edgecolor='black')\n",
                "plt.axvline(n*p, color='r', linestyle='--', linewidth=2, label=f'E[X] = {n*p}')\n",
                "plt.xlabel('k (성공 횟수)')\n",
                "plt.ylabel('P(X = k)')\n",
                "plt.title(f'Binomial Distribution: n={n}, p={p}')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 범주형 분포 (Categorical)\n",
                "\n",
                "**설명**: $K$개 범주 중 하나 선택\n",
                "\n",
                "- $P(Y = i) = p_i$, $\\sum_{i=1}^K p_i = 1$\n",
                "- $K=2$일 때 베르누이와 동일\n",
                "\n",
                "**ML 활용**: 다항 분류 출력(Softmax), 언어 모델, 강화학습 행동 선택"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.4 포아송 분포 (Poisson)\n",
                "\n",
                "**설명**: 단위 시간/공간당 사건 발생 횟수\n",
                "\n",
                "$$P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$\n",
                "\n",
                "- $E[X] = \\text{Var}(X) = \\lambda$\n",
                "\n",
                "**ML 활용**: 포아송 회귀, 카운트 데이터 모델링, 드문 이벤트 예측"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 포아송 분포 비교\n",
                "lambdas = [1, 5, 10]\n",
                "k_values = np.arange(0, 25)\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "for lam in lambdas:\n",
                "    pmf = stats.poisson.pmf(k_values, lam)\n",
                "    plt.plot(k_values, pmf, 'o-', label=f'λ={lam}, E[X]={lam}', markersize=5)\n",
                "\n",
                "plt.xlabel('k (발생 횟수)')\n",
                "plt.ylabel('P(X = k)')\n",
                "plt.title('Poisson Distribution for Different λ')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.5 지수분포 (Exponential)\n",
                "\n",
                "**설명**: 사건 발생까지 대기 시간 (연속형)\n",
                "\n",
                "$$f(x) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0$$\n",
                "\n",
                "- $E[X] = \\frac{1}{\\lambda}$\n",
                "- $\\text{Var}(X) = \\frac{1}{\\lambda^2}$\n",
                "- **무기억성**: $P(X > s+t | X > s) = P(X > t)$\n",
                "\n",
                "**ML 활용**: 생존 분석, 신뢰성 공학, 포아송 프로세스의 간격 분포"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 지수분포 vs 감마분포\n",
                "x = np.linspace(0, 10, 1000)\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "\n",
                "# 지수분포 (감마의 특수 케이스: α=1)\n",
                "lam = 1\n",
                "exp_pdf = stats.expon.pdf(x, scale=1/lam)\n",
                "plt.plot(x, exp_pdf, linewidth=2, label=f'Exponential(λ={lam})')\n",
                "\n",
                "# 감마분포 (여러 지수분포의 합)\n",
                "for alpha in [2, 3, 5]:\n",
                "    gamma_pdf = stats.gamma.pdf(x, alpha, scale=1/lam)\n",
                "    plt.plot(x, gamma_pdf, linewidth=2, label=f'Gamma(α={alpha}, λ={lam})')\n",
                "\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('f(x)')\n",
                "plt.title('Exponential vs Gamma Distributions')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.6 정규분포 (Normal/Gaussian)\n",
                "\n",
                "**가장 중요한 분포!**\n",
                "\n",
                "$$f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n",
                "\n",
                "- $E[X] = \\mu$\n",
                "- $\\text{Var}(X) = \\sigma^2$\n",
                "- 표기: $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n",
                "\n",
                "**68-95-99.7 규칙**:\n",
                "- $P(\\mu - \\sigma \\leq X \\leq \\mu + \\sigma) \\approx 0.68$\n",
                "- $P(\\mu - 2\\sigma \\leq X \\leq \\mu + 2\\sigma) \\approx 0.95$\n",
                "- $P(\\mu - 3\\sigma \\leq X \\leq \\mu + 3\\sigma) \\approx 0.997$\n",
                "\n",
                "**ML 활용**: 선형회귀 오차항, 가우시안 나이브 베이즈, GMM, VAE, 가중치 초기화"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 정규분포와 68-95-99.7 규칙\n",
                "mu, sigma = 0, 1\n",
                "x = np.linspace(-4, 4, 1000)\n",
                "pdf = stats.norm.pdf(x, mu, sigma)\n",
                "\n",
                "plt.figure(figsize=(12, 7))\n",
                "plt.plot(x, pdf, 'b-', linewidth=2, label='PDF')\n",
                "\n",
                "# 68-95-99.7 표시\n",
                "for k, alpha, label in [(1, 0.3, '68%'), (2, 0.2, '95%'), (3, 0.1, '99.7%')]:\n",
                "    x_range = np.linspace(mu - k*sigma, mu + k*sigma, 100)\n",
                "    y_range = stats.norm.pdf(x_range, mu, sigma)\n",
                "    plt.fill_between(x_range, y_range, alpha=alpha, label=f'±{k}σ ({label})')\n",
                "\n",
                "plt.axvline(mu, color='r', linestyle='--', linewidth=2, label=f'μ = {mu}')\n",
                "plt.xlabel('x')\n",
                "plt.ylabel('f(x)')\n",
                "plt.title(f'Normal Distribution N({mu}, {sigma}²)')\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "# 검증\n",
                "print(\"68-95-99.7 규칙 검증:\")\n",
                "for k in [1, 2, 3]:\n",
                "    prob = stats.norm.cdf(mu + k*sigma, mu, sigma) - stats.norm.cdf(mu - k*sigma, mu, sigma)\n",
                "    print(f\"P(μ-{k}σ ≤ X ≤ μ+{k}σ) = {prob:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 중심극한정리 (Central Limit Theorem)\n",
                "\n",
                "### 정리\n",
                "\n",
                "독립 확률변수들의 **표본평균**은 표본 크기가 커질수록 정규분포로 수렴:\n",
                "\n",
                "$$\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i \\approx \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$\n",
                "\n",
                "### 의의\n",
                "\n",
                "- 개별 분포의 형태와 **무관**\n",
                "- 신뢰구간, 가설검정의 이론적 근거\n",
                "- 자연현상이 정규분포를 따르는 이유\n",
                "\n",
                "**ML 활용**: SGD의 그래디언트 분포, 앙상블 예측 분산 감소, 오차항 가정"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 중심극한정리 시뮬레이션\n",
                "# 지수분포(편향 분포)의 표본평균 → 점점 정규분포로\n",
                "\n",
                "lam = 1  # 지수분포 모수\n",
                "sample_sizes = [1, 5, 30]\n",
                "n_simulations = 10000\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "for idx, n in enumerate(sample_sizes):\n",
                "    # n개씩 샘플링하여 평균 계산\n",
                "    samples = np.random.exponential(1/lam, (n_simulations, n))\n",
                "    sample_means = samples.mean(axis=1)\n",
                "    \n",
                "    ax = axes[idx]\n",
                "    ax.hist(sample_means, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
                "    \n",
                "    # 이론적 정규분포 (CLT)\n",
                "    mu_theory = 1/lam\n",
                "    sigma_theory = (1/lam) / np.sqrt(n)\n",
                "    x = np.linspace(sample_means.min(), sample_means.max(), 100)\n",
                "    ax.plot(x, stats.norm.pdf(x, mu_theory, sigma_theory), 'r-', linewidth=2, label='이론 N(μ, σ²/n)')\n",
                "    \n",
                "    ax.set_title(f'표본 크기 n={n}')\n",
                "    ax.set_xlabel('표본평균')\n",
                "    ax.set_ylabel('밀도')\n",
                "    ax.legend()\n",
                "    ax.grid(alpha=0.3)\n",
                "\n",
                "plt.suptitle('중심극한정리: 지수분포의 표본평균 분포', fontsize=14, y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"해석: 표본 크기가 커질수록 (좌→우) 분포가 정규분포에 가까워진다!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Softmax와 확률의 연결\n",
                "\n",
                "### Softmax 함수\n",
                "\n",
                "Logits $z = [z_1, z_2, \\ldots, z_K]$를 확률 분포로 변환:\n",
                "\n",
                "$$\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
                "\n",
                "### 왜 확률인가?\n",
                "\n",
                "1. **비음성**: $\\sigma(z)_i \\geq 0$ (지수함수는 항상 양수)\n",
                "2. **정규화**: $\\sum_{i=1}^{K} \\sigma(z)_i = 1$\n",
                "\n",
                "따라서 PMF의 공리를 만족!\n",
                "\n",
                "### 해석\n",
                "\n",
                "$$\\sigma(z)_i = P(Y = i | X)$$\n",
                "\n",
                "입력 $X$가 주어졌을 때 클래스 $i$일 조건부 확률 = **Categorical Distribution**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def softmax(z):\n",
                "    \"\"\"Numerically stable softmax\"\"\"\n",
                "    exp_z = np.exp(z - np.max(z))\n",
                "    return exp_z / np.sum(exp_z)\n",
                "\n",
                "# 3개 클래스 분류\n",
                "logits = np.array([3.0, 1.0, 0.2])\n",
                "probs = softmax(logits)\n",
                "\n",
                "print(\"=== Softmax 예제 ===\")\n",
                "print(f\"Logits: {logits}\")\n",
                "print(f\"Softmax: {probs}\")\n",
                "print(f\"Sum: {np.sum(probs):.10f} (should be 1.0)\")\n",
                "print(f\"\\n해석:\")\n",
                "for i, p in enumerate(probs):\n",
                "    print(f\"  P(Y = {i} | X) = {p:.4f} ({p*100:.2f}%)\")\n",
                "\n",
                "# Temperature scaling\n",
                "def softmax_temperature(z, T=1.0):\n",
                "    z_scaled = z / T\n",
                "    exp_z = np.exp(z_scaled - np.max(z_scaled))\n",
                "    return exp_z / np.sum(exp_z)\n",
                "\n",
                "temperatures = [0.5, 1.0, 2.0, 5.0]\n",
                "plt.figure(figsize=(12, 4))\n",
                "x = np.arange(len(logits))\n",
                "width = 0.2\n",
                "\n",
                "for i, T in enumerate(temperatures):\n",
                "    probs_T = softmax_temperature(logits, T)\n",
                "    plt.bar(x + i*width, probs_T, width, label=f'T = {T}', alpha=0.8)\n",
                "\n",
                "plt.xlabel('클래스')\n",
                "plt.ylabel('확률')\n",
                "plt.title('Temperature Scaling 효과')\n",
                "plt.xticks(x + width * 1.5, ['Class 0', 'Class 1', 'Class 2'])\n",
                "plt.legend()\n",
                "plt.grid(alpha=0.3, axis='y')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n온도 효과: T>1이면 균등, T<1이면 뾰족\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Cross-Entropy Loss와 MLE\n",
                "\n",
                "### Cross-Entropy Loss\n",
                "\n",
                "$$L = -\\sum_{i=1}^{K} y_i \\log \\hat{y}_i$$\n",
                "\n",
                "- $y$: one-hot 인코딩된 정답\n",
                "- $\\hat{y} = \\sigma(z)$: Softmax 출력\n",
                "\n",
                "### 정보 이론적 해석\n",
                "\n",
                "두 분포 $p$와 $q$ 사이의 거리:\n",
                "\n",
                "$$H(p, q) = -\\sum_i p(i) \\log q(i)$$\n",
                "\n",
                "최소화하면 $q \\rightarrow p$\n",
                "\n",
                "### Maximum Likelihood Estimation (MLE)\n",
                "\n",
                "$$\\theta^* = \\arg\\max_{\\theta} P(\\text{data} | \\theta)$$\n",
                "\n",
                "**중요**: Minimize Cross-Entropy = Maximize Log-Likelihood!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def cross_entropy(y_true, y_pred):\n",
                "    return -np.sum(y_true * np.log(y_pred + 1e-10))\n",
                "\n",
                "# True label: class 2\n",
                "y_true = np.array([0, 0, 1])\n",
                "\n",
                "predictions = [\n",
                "    np.array([0.1, 0.1, 0.8]),  # 좋은 예측\n",
                "    np.array([0.3, 0.4, 0.3]),  # 나쁜 예측\n",
                "    np.array([0.0, 0.0, 1.0]),  # 완벽한 예측\n",
                "]\n",
                "\n",
                "print(\"=== Cross-Entropy Loss ===\")\n",
                "for i, y_pred in enumerate(predictions):\n",
                "    loss = cross_entropy(y_true, y_pred)\n",
                "    print(f\"예측 {i+1}: {y_pred}, Loss = {loss:.4f}, P(정답) = {y_pred[2]:.1f}\")\n",
                "\n",
                "# Loss landscape\n",
                "p_true = np.linspace(0.01, 0.99, 100)\n",
                "losses = [cross_entropy(y_true, np.array([(1-p)/2, (1-p)/2, p])) for p in p_true]\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(p_true, losses, 'b-', linewidth=2)\n",
                "plt.xlabel('P(true class)')\n",
                "plt.ylabel('Cross-Entropy Loss')\n",
                "plt.title('Loss vs. Predicted Probability')\n",
                "plt.grid(alpha=0.3)\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n해석: 정답 확률이 1에 가까울수록 loss → 0\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. 연습문제\n",
                "\n",
                "### 문제 1: 베이즈 정리\n",
                "\n",
                "두 동전이 있습니다:\n",
                "- 동전 A: 공정 (P(앞면) = 0.5)\n",
                "- 동전 B: 편향 (P(앞면) = 0.7)\n",
                "\n",
                "랜덤하게 하나를 선택하여 던졌더니 앞면이 나왔습니다.\n",
                "\n",
                "1. P(동전 A | 앞면)을 구하시오\n",
                "2. 같은 동전을 다시 던졌을 때 앞면이 나올 확률은?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 문제 1 풀이\n",
                "P_A = 0.5\n",
                "P_B = 0.5\n",
                "P_heads_given_A = 0.5\n",
                "P_heads_given_B = 0.7\n",
                "\n",
                "# Evidence\n",
                "P_heads = P_heads_given_A * P_A + P_heads_given_B * P_B\n",
                "\n",
                "# Posterior\n",
                "P_A_given_heads = (P_heads_given_A * P_A) / P_heads\n",
                "P_B_given_heads = (P_heads_given_B * P_B) / P_heads\n",
                "\n",
                "print(\"=== 문제 1 풀이 ===\")\n",
                "print(f\"1. P(동전 A | 앞면) = {P_A_given_heads:.4f}\")\n",
                "print(f\"   P(동전 B | 앞면) = {P_B_given_heads:.4f}\")\n",
                "\n",
                "# 다시 던졌을 때\n",
                "P_heads_again = P_heads_given_A * P_A_given_heads + P_heads_given_B * P_B_given_heads\n",
                "print(f\"2. P(다시 앞면) = {P_heads_again:.4f}\")\n",
                "print(f\"   → 처음({P_heads:.2f})보다 높아짐!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 문제 2: 정규분포\n",
                "\n",
                "학생들의 시험 점수가 평균 70, 표준편차 10인 정규분포를 따릅니다.\n",
                "\n",
                "1. 85점의 Z-score는?\n",
                "2. 80점 이상 받을 확률은?\n",
                "3. 상위 10%의 최소 점수는?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 문제 2 풀이\n",
                "mu, sigma = 70, 10\n",
                "\n",
                "print(\"=== 문제 2: N(70, 10²) ===\")\n",
                "\n",
                "# 1. Z-score\n",
                "x = 85\n",
                "z = (x - mu) / sigma\n",
                "print(f\"1. Z-score of {x}: z = {z:.2f}\")\n",
                "\n",
                "# 2. P(X ≥ 80)\n",
                "prob_80 = 1 - stats.norm.cdf(80, mu, sigma)\n",
                "print(f\"2. P(X ≥ 80) = {prob_80:.4f}\")\n",
                "\n",
                "# 3. 상위 10%\n",
                "top_10 = stats.norm.ppf(0.9, mu, sigma)\n",
                "print(f\"3. 상위 10% 최소 점수 = {top_10:.2f}점\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. 요약 정리\n",
                "\n",
                "### 핵심 개념\n",
                "\n",
                "1. **확률**: 사건 발생 가능성의 척도 (0~1)\n",
                "2. **조건부 확률**: $P(A|B) = \\frac{P(A \\cap B)}{P(B)}$\n",
                "3. **베이즈 정리**: Prior × Likelihood → Posterior\n",
                "4. **확률변수**: 표본공간 → 실수의 함수\n",
                "5. **기댓값**: 확률분포의 평균\n",
                "6. **분산**: 평균 주변 산포도\n",
                "7. **중심극한정리**: 표본평균 → 정규분포\n",
                "\n",
                "### 주요 분포\n",
                "\n",
                "| 분포 | 타입 | 파라미터 | E[X] | Var(X) | ML 활용 |\n",
                "|------|------|----------|------|--------|--------|\n",
                "| Bernoulli | 이산 | p | p | p(1-p) | 이진 분류 |\n",
                "| Binomial | 이산 | n, p | np | np(1-p) | A/B 테스트 |\n",
                "| Poisson | 이산 | λ | λ | λ | 카운트 데이터 |\n",
                "| Categorical | 이산 | p₁,...,pₖ | - | - | 다항 분류 |\n",
                "| Exponential | 연속 | λ | 1/λ | 1/λ² | 생존 분석 |\n",
                "| Normal | 연속 | μ, σ² | μ | σ² | **모든 곳** |\n",
                "\n",
                "### ML에서 확률의 역할\n",
                "\n",
                "- **모델링**: 데이터 분포 가정\n",
                "- **추론**: 베이지안 방법\n",
                "- **학습**: MLE, MAP\n",
                "- **평가**: 불확실성 정량화\n",
                "- **정규화**: Prior = Regularization\n",
                "\n",
                "---\n",
                "\n",
                "## 참고자료\n",
                "\n",
                "- Introduction to Probability (Bertsekas & Tsitsiklis)\n",
                "- Pattern Recognition and Machine Learning (Bishop)\n",
                "- Dive into Deep Learning (d2l.ai)\n",
                "- Stanford CS229 Probability Review"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}